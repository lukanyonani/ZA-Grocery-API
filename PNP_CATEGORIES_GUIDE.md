# Pick n Pay Scraper - Categories Guide

## üéØ Overview

The PnP scraper now supports **25 different categories**! You can scrape from specific categories like Beverages, Snacks, Personal Care, and more.

## üìã Available Categories

| Category Key | Category Name | Example Use |
|--------------|---------------|-------------|
| `promotions` | Promotions | Special deals and promotions |
| `food-cupboard` | Food Cupboard | Pantry staples, canned goods |
| `personal-care` | Personal Care & Hygiene | Toiletries, cosmetics |
| `liquor` | Liquor Store | Wines, spirits, beer |
| `home-appliances` | Home, Appliances & Outdoor | Appliances, outdoor items |
| `snacks` | Chocolates, Chips & Snacks | Snacks and treats |
| `beverages` | Beverages | Soft drinks, juices |
| `home` | Home & Appliances | Home goods |
| `household` | Household & Cleaning | Cleaning products |
| `outdoor` | Outdoor & DIY | DIY and outdoor |
| `dairy` | Milk, Dairy & Eggs | Dairy products |
| `health` | Health & Wellness | Health products |
| `pet` | Pet Care | Pet food and supplies |
| `frozen` | Frozen Food | Frozen items |
| `stationery` | Stationery | Office supplies |
| `baby` | Baby | Baby products |
| `coffee-tea` | Coffee, Tea & Hot Drinks | Hot beverages |
| `fresh-produce` | Fresh Fruit & Vegetables | Fresh produce |
| `electronics` | Electronics & Office | Electronics |
| `bakery` | Bakery | Bakery items |
| `meat` | Fresh Meat, Poultry & Seafood | Fresh meats |
| `deli` | Deli & Party | Deli items |
| `toys` | Toys & Games | Toys |
| `ready-meals` | Ready Meals & Desserts | Ready-to-eat meals |
| `flowers` | Flowers & Plants | Flowers and plants |

## üöÄ Quick Start

### 1. List All Categories

```python
from pnp_scraper_v2 import list_categories

list_categories()
```

### 2. Scrape a Specific Category

```python
from pnp_scraper_v2 import PnPSmartScraper

# Scrape beverages
scraper = PnPSmartScraper(category='beverages')
products = scraper.scrape(max_pages=2)
scraper.save_json()  # Saves to pnp_beverages_products.json
```

### 3. Scrape Multiple Categories

```python
categories = ['snacks', 'beverages', 'dairy']

for category in categories:
    scraper = PnPSmartScraper(category=category)
    products = scraper.scrape(max_pages=1)
    scraper.save_json()
    print(f"{category}: {len(products)} products")
```

## üíª Usage Examples

### Example 1: Scrape Snacks

```python
from pnp_scraper_v2 import PnPSmartScraper

scraper = PnPSmartScraper(category='snacks', headless=True)
products = scraper.scrape(max_pages=2)

if products:
    scraper.save_json()  # pnp_snacks_products.json
    scraper.save_csv()   # pnp_snacks_products.csv
    print(f"Found {len(products)} snacks")
```

**Result**: ~78 products per page

### Example 2: Scrape Liquor Store

```python
scraper = PnPSmartScraper(category='liquor')
products = scraper.scrape(max_pages=3)

# Custom filenames
scraper.save_json('my_liquor_data.json')
scraper.save_csv('my_liquor_data.csv')
```

### Example 3: Scrape with Limits

```python
scraper = PnPSmartScraper(category='personal-care')
products = scraper.scrape(max_pages=5, max_products=100)
# Will stop after 100 products even if more pages available
```

### Example 4: Compare Categories

```python
categories = ['snacks', 'beverages', 'dairy', 'frozen']
results = {}

for cat in categories:
    scraper = PnPSmartScraper(category=cat)
    prods = scraper.scrape(max_pages=1)
    results[cat] = len(prods)

# Print comparison
for cat, count in sorted(results.items(), key=lambda x: x[1], reverse=True):
    print(f"{cat}: {count} products")
```

### Example 5: Scrape All Food Categories

```python
food_categories = [
    'food-cupboard', 'snacks', 'beverages', 'dairy',
    'frozen', 'fresh-produce', 'bakery', 'meat', 'ready-meals'
]

for category in food_categories:
    print(f"\nScraping {category}...")
    scraper = PnPSmartScraper(category=category)
    products = scraper.scrape(max_pages=1)
    
    if products:
        scraper.save_json()
        print(f"‚úì {len(products)} products")
```

## üìÅ File Naming

Files are automatically named based on the category:

```python
# Category: 'snacks'
scraper.save_json()  # ‚Üí pnp_snacks_products.json
scraper.save_csv()   # ‚Üí pnp_snacks_products.csv

# Category: 'liquor'
scraper.save_json()  # ‚Üí pnp_liquor_products.json
scraper.save_csv()   # ‚Üí pnp_liquor_products.csv

# Custom filename
scraper.save_json('my_custom_name.json')
```

## ‚è±Ô∏è Performance

- **Time per page**: ~30-35 seconds (Selenium + API capture)
- **Products per page**: ~30-80 (varies by category)
- **Delay between pages**: 3 seconds (respectful scraping)

### Time Estimates by Pages

| Pages | Time | Products (approx) |
|-------|------|-------------------|
| 1 page | ~30 sec | 30-80 |
| 2 pages | ~65 sec | 60-160 |
| 3 pages | ~100 sec | 90-240 |
| 5 pages | ~170 sec | 150-400 |

## üéì Advanced Usage

### 1. Scrape and Analyze

```python
from pnp_scraper_v2 import PnPSmartScraper

scraper = PnPSmartScraper(category='beverages')
products = scraper.scrape(max_pages=3)

# Analyze prices
prices = [p['promotional_price'] for p in products if p.get('promotional_price')]
print(f"Average: R{sum(prices)/len(prices):.2f}")
print(f"Range: R{min(prices):.2f} - R{max(prices):.2f}")

# Filter products
cheap_items = [p for p in products if p.get('promotional_price', 999) < 50]
print(f"Items under R50: {len(cheap_items)}")
```

### 2. Scrape Multiple Categories to Combined File

```python
import json

all_products = []
categories = ['snacks', 'beverages', 'dairy']

for category in categories:
    scraper = PnPSmartScraper(category=category)
    products = scraper.scrape(max_pages=1)
    
    # Add category field
    for p in products:
        p['category'] = category
    
    all_products.extend(products)

# Save combined file
with open('pnp_all_food.json', 'w') as f:
    json.dump(all_products, f, indent=2)

print(f"Total: {len(all_products)} products")
```

### 3. Error Handling

```python
from pnp_scraper_v2 import PnPSmartScraper, CATEGORIES

for category_key in CATEGORIES.keys():
    try:
        print(f"Scraping {category_key}...")
        scraper = PnPSmartScraper(category=category_key)
        products = scraper.scrape(max_pages=1)
        
        if products:
            scraper.save_json()
            print(f"‚úì {len(products)} products")
    except Exception as e:
        print(f"‚úó Error: {e}")
        continue
```

## üÜö Category vs Promotions

### Promotions (Default)
- Special deals and discounts
- Products on promotion across all categories
- Usually has promotional pricing

### Specific Categories
- All products in that category (promotions + regular)
- May or may not have promotional prices
- More comprehensive product listings

## üìä Example Test Results

**Tested categories** (1 page each):

| Category | Products | Time |
|----------|----------|------|
| Snacks | 78 | 31 sec |
| Beverages | 65 | 29 sec |
| Promotions | 102 | 34 sec |

## üí° Tips & Best Practices

1. **Start Small**: Test with 1-2 pages first
2. **Use Appropriate Categories**: Choose the right category for your needs
3. **Respect Rate Limits**: Built-in 3-second delay between pages
4. **Save Frequently**: Auto-saves after each category
5. **Monitor Output**: Watch console for progress and errors
6. **Custom Filenames**: Use custom names when scraping multiple runs

## ‚ö†Ô∏è Important Notes

1. **Category validation**: Invalid categories raise a `ValueError`
2. **Pagination**: All categories support pagination
3. **Same data format**: All categories return the same product structure
4. **Headless mode**: Run with `headless=True` for production
5. **ChromeDriver**: Automatically managed by `webdriver-manager`

## üîç Validation

Check if a category exists:

```python
from pnp_scraper_v2 import CATEGORIES

if 'beverages' in CATEGORIES:
    print(f"‚úì Category: {CATEGORIES['beverages']['name']}")

# Get category name
category_name = CATEGORIES['snacks']['name']
# Output: "Chocolates, Chips & Snacks"
```

## üìö Complete Working Example

```python
#!/usr/bin/env python3
from pnp_scraper_v2 import PnPSmartScraper, list_categories

def main():
    # 1. List categories
    print("Available categories:")
    list_categories()
    
    # 2. Scrape beverages
    print("\nScraping beverages...")
    scraper = PnPSmartScraper(category='beverages', headless=True)
    products = scraper.scrape(max_pages=2)
    
    # 3. Save results
    if products:
        scraper.save_json()
        scraper.save_csv()
        scraper.print_summary()
        
        # 4. Analyze
        prices = [p['promotional_price'] for p in products 
                  if p.get('promotional_price')]
        if prices:
            print(f"\nPrice Analysis:")
            print(f"  Average: R{sum(prices)/len(prices):.2f}")
            print(f"  Cheapest: R{min(prices):.2f}")
            print(f"  Most expensive: R{max(prices):.2f}")

if __name__ == "__main__":
    main()
```

## üéâ Summary

- **25 categories** available
- **Full pagination** support for all
- **Automatic file naming** by category
- **Same API** for all categories
- **Production ready** with error handling

---

**See also**:
- `pnp_categories_examples.py` - More examples
- `PNP_PAGINATION_GUIDE.md` - Pagination details
- `README.md` - Project overview

**Updated**: October 6, 2025  
**Feature**: Multi-Category Support  
**Status**: ‚úÖ Production Ready

